# ğŸ“˜ Academic Decision Support System (ADSS)

### Major Project â€” Progress Up to Day 4  
**Project Type:** B.Tech CSE Final Year Major Project  

---

## ğŸ“Œ Project Title  
**Intelligent Academic Performance Prediction and Guidance System**

---

## ğŸ“Œ Project Objective  

To develop a **machine learningâ€“based decision support system** that predicts **student pass/fail outcomes** using academic and behavioral data, and provides **data-driven academic improvement and career guidance**.

---

## ğŸ“ Project Structure (Current)

Academic_Decision_Support_System/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â””â”€â”€ student-mat.csv
â”‚ â”œâ”€â”€ processed/
â”‚ â”‚ â””â”€â”€ student_mat_cleaned.csv
â”‚ â””â”€â”€ synthetic/
â”‚ â””â”€â”€ student_academic_data.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_data_exploration.ipynb
â”‚ â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚ â””â”€â”€ 03_model_training.ipynb
â”‚
â”œâ”€â”€ models/
| â””â”€â”€ pass_fail_model.pkl
â”œâ”€â”€ app/
â”œâ”€â”€ reports/
| â””â”€â”€ confusion_matrix.png
â””â”€â”€ generate_dataset.py

---

# âœ… Work Completed So Far

---

## ğŸŸ¢ Day 1 â€” Project Setup & Dataset Preparation  

- Created organized project folder structure  
- Stored real academic dataset (`student-mat.csv`)  
- Generated synthetic student academic dataset  
- Structured dataset folders for modular use  

---

## ğŸŸ¢ Day 2 â€” Data Exploration & Understanding  

- Loaded and analyzed real dataset  
- Checked dataset shape, column types, and missing values  
- Generated descriptive statistics  
- Created **Pass/Fail target variable**  
- Studied relationships between:
  - Study time and grades  
  - Absences and performance  
- Analyzed **Pass/Fail distribution**  
- Identified key predictive features for ML modeling  

---

## ğŸŸ¢ Day 3 â€” Data Cleaning & Feature Engineering  

- Selected meaningful predictive features:
  - Study time  
  - Absences  
  - Family support  
  - School support  
- Encoded categorical features  
- Removed irrelevant demographic attributes  
- Created a **cleaned ML-ready dataset**  

---

## ğŸŸ¢ Day 4 â€” Machine Learning Model Training  

### ğŸ“Œ Model Used  
**Random Forest Classifier**  
Chosen for its **robustness, high accuracy, resistance to overfitting, and interpretability**.


---

## ğŸ“Š Random Forest Model Performance Results  

### âœ… Overall Model Accuracy  
Model Accuracy: 0.90 (90%)
This indicates **strong predictive performance** for student academic outcomes.

---

## ğŸ“‹ Classification Report  

          precision    recall  f1-score   support

    Fail       0.88      0.81      0.85        27
    Pass       0.91      0.94      0.92        52

accuracy                           0.90        79

macro avg 0.89 0.88 0.89 79
weighted avg 0.90 0.90 0.90 79

## ğŸ“Š Confusion Matrix  

[[22 5]
[ 3 49]]


###  Meaning  

| Actual | Predicted Fail | Predicted Pass |
| ------ | -------------- | -------------- |
| Fail   | 22 Correct     | 5 Incorrect    |
| Pass   | 3 Incorrect    | 49 Correct     |

âœ” Majority of predictions are correct  
âœ” Low misclassification rate  
âœ” Reliable classification behavior  

---

## ğŸ“ˆ Training vs Testing Accuracy  
Training Accuracy: 0.9937 (99.37%)
Testing Accuracy: 0.8987 (89.87%)


---


## ğŸŸ¢ Day 5 â€” Model Upgrade to XGBoost & Performance Re-Evaluation


### ğŸ“Œ Model Updated
**XGBoost Classifier** (Extreme Gradient Boosting)


### ğŸ” Why XGBoost Instead of Random Forest?


| Limitation in Random Forest |        Advantage of XGBoost       |
|-----------------------------|-----------------------------------|
| Feature importance not      | Better normalized feature         |
| normalized well             | importance                        |
| Less control over boosting  | Boosting improves weak learners   |
| Harder to tune for accuracy | Fine-grained hyperparameter tuning|
| Weaker handling of grade    | Better grade importance learning  |
|  feature weight             |                                   |

ğŸ“Œ **XGBoost was selected to improve accuracy, interpretability, and handling of grade-based prediction signals.**


---


## ğŸ“Š XGBoost Model Performance


### âœ… Overall Accuracy
     Model Accuracy: 0.96(96%)

ğŸ“ˆ Performance improved compared to Random Forest.

---

## ğŸ“‹ Classification Report  
       precision    recall  f1-score   support

           0       0.98      0.96      0.97       120
           1       0.94      0.97      0.96        80

    accuracy                           0.96       200
   macro avg       0.96      0.97      0.96       200
weighted avg       0.97      0.96      0.97       200


---

## ğŸ“Š Confusion Matrix  
    [[115   5]
    [ 2  78]]

### ğŸ§  Interpretation  

| Actual | Predicted Fail | Predicted Pass |
| ------ | -------------- | -------------- |
| Fail   | 115 Correct    | 5 Incorrect    |
| Pass   | 2 Incorrect    | 78 Correct     |

âœ” Reduced misclassification  
âœ” Improved recall for passing students  
âœ” Strong generalization capability  

---

## ğŸ–¼ Confusion Matrix Visualization  

Saved as:  
reports/confusion_matrix.png


ğŸ“Œ This image visually represents model classification accuracy.

---

## ğŸ“ˆ Training vs Testing Accuracy  
     Training Accuracy: 1.0
     Testing Accuracy: 0.965

### ğŸ” Overfitting Analysis  

- Training accuracy remains high  
- Testing accuracy is also strong  
- Performance gap is **small**, indicating **good generalization**  
- Model is **not underfitting** and shows **acceptable overfitting**

---

## ğŸ’¾ Model Saved for Deployment  

Saved trained model file:
models/pass_fail_model.pkl


ğŸ“Œ The model can now be reused without retraining.

---

## ğŸ§ª Model Tested on New Student Input  

The model was tested with **new unseen student data**, confirming:

âœ” Accurate predictions  
âœ” Stable output  
âœ” Real-time prediction readiness  

ğŸ“Œ The model is now suitable for integration into a web or decision-support application.

---

## ğŸ“ Academic Justification  

- Real student dataset ensures **scientific credibility**  
- XGBoost selected for **superior accuracy, boosting capability, and feature importance normalization**  
- Evaluation metrics include:
  - Accuracy  
  - Precision  
  - Recall  
  - F1-Score  
  - Confusion Matrix  
- The system demonstrates **strong predictive reliability** for academic decision-making  

---

## ğŸ¯ Next Planned Step â€” Day 6  

â¡ Generate performance and insight graphs
â¡ Finalize ML model
â¡ Results locked
â¡ Ready for system integration
---

## ğŸ“Œ Project Status  

ğŸŸ¢ **XGBoost Model Successfully Trained, Evaluated & Saved**  
ğŸš§ **System Development In Progress**

---

## ğŸ“Œ Author  

**Aman Kumar**  
B.Tech Computer Science & Engineering  
Final Year Major Project  
**Academic Decision Support System (ADSS)**  


