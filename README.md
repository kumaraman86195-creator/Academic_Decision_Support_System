# ğŸ“˜ Academic Decision Support System (ADSS)

### Major Project â€” Progress Up to Day 4  
**Project Type:** B.Tech CSE Final Year Major Project  
ss---

## ğŸ“Œ Project Objective  

To develop a **machine learningâ€“based decision support system** that predicts **student pass/fail outcomes** using academic and behavioral data, and provides **data-driven academic improvement and career guidance**.

---

## ğŸ“ Project Structure (Current)

Academic_Decision_Support_System/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â””â”€â”€ student-mat.csv
â”‚ â”œâ”€â”€ processed/
â”‚ â”‚ â””â”€â”€ student_mat_cleaned.csv
â”‚ â””â”€â”€ synthetic/
â”‚ â””â”€â”€ student_academic_data.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_data_exploration.ipynb
â”‚ â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚ â””â”€â”€ 03_model_training.ipynb
â”‚
â”œâ”€â”€ models/
| â””â”€â”€ pass_fail_model.pkl
|
â”œâ”€â”€ src/
|   â”œâ”€â”€recommendation/
|   |              â”œâ”€â”€weak_subject_detection.py
|   |              â””â”€â”€weak_sub_feedback_test.py
|   â”œâ”€â”€data_loder.py
|   â”œâ”€â”€preprocess.py
|   â”œâ”€â”€train_model.py
|   â”œâ”€â”€predict.py
|   â”œâ”€â”€evaluate_model.py
|   â””â”€â”€__init__.py
|
|
|
â”œâ”€â”€ app/
â”œâ”€â”€ reports/
| â””â”€â”€ confusion_matrix.png
â”œâ”€â”€ generate_dataset.py
|
â””â”€â”€test.py

---

# âœ… Work Completed So Far

---

## ğŸŸ¢ Day 1 â€” Project Setup & Dataset Preparation  

- Created organized project folder structure  
- Stored real academic dataset (`student-mat.csv`)  
- Generated synthetic student academic dataset  
- Structured dataset folders for modular use  

---

## ğŸŸ¢ Day 2 â€” Data Exploration & Understanding  

- Loaded and analyzed real dataset  
- Checked dataset shape, column types, and missing values  
- Generated descriptive statistics  
- Created **Pass/Fail target variable**  
- Studied relationships between:
  - Study time and grades  
  - Absences and performance  
- Analyzed **Pass/Fail distribution**  
- Identified key predictive features for ML modeling  

---

## ğŸŸ¢ Day 3 â€” Data Cleaning & Feature Engineering  

- Selected meaningful predictive features:
  - Study time  
  - Absences  
  - Family support  
  - School support  
- Encoded categorical features  
- Removed irrelevant demographic attributes  
- Created a **cleaned ML-ready dataset**  

---

## ğŸŸ¢ Day 4 â€” Machine Learning Model Training  

### ğŸ“Œ Model Used  
**Random Forest Classifier**  
Chosen for its **robustness, high accuracy, resistance to overfitting, and interpretability**.


---

## ğŸ“Š Random Forest Model Performance Results  

### âœ… Overall Model Accuracy  
Model Accuracy: 0.90 (90%)
This indicates **strong predictive performance** for student academic outcomes.

---

## ğŸ“‹ Classification Report  

          precision    recall  f1-score   support

    Fail       0.88      0.81      0.85        27
    Pass       0.91      0.94      0.92        52

accuracy                           0.90        79

macro avg 0.89 0.88 0.89 79
weighted avg 0.90 0.90 0.90 79

## ğŸ“Š Confusion Matrix  

[[22 5]
[ 3 49]]


###  Meaning  

| Actual | Predicted Fail | Predicted Pass |
| ------ | -------------- | -------------- |
| Fail   | 22 Correct     | 5 Incorrect    |
| Pass   | 3 Incorrect    | 49 Correct     |

âœ” Majority of predictions are correct  
âœ” Low misclassification rate  
âœ” Reliable classification behavior  

---

## ğŸ“ˆ Training vs Testing Accuracy  
Training Accuracy: 0.9937 (99.37%)
Testing Accuracy: 0.8987 (89.87%)


---


## ğŸŸ¢ Day 5 â€” Model Upgrade to XGBoost & Performance Re-Evaluation


### ğŸ“Œ Model Updated
**XGBoost Classifier** (Extreme Gradient Boosting)


### ğŸ” Why XGBoost Instead of Random Forest?


| Limitation in Random Forest |        Advantage of XGBoost       |
|-----------------------------|-----------------------------------|
| Feature importance not      | Better normalized feature         |
| normalized well             | importance                        |
| Less control over boosting  | Boosting improves weak learners   |
| Harder to tune for accuracy | Fine-grained hyperparameter tuning|
| Weaker handling of grade    | Better grade importance learning  |
|  feature weight             |                                   |

ğŸ“Œ **XGBoost was selected to improve accuracy, interpretability, and handling of grade-based prediction signals.**


---


## ğŸ“Š XGBoost Model Performance


### âœ… Overall Accuracy
     Model Accuracy: 0.96(96%)

ğŸ“ˆ Performance improved compared to Random Forest.

---

## ğŸ“‹ Classification Report  
       precision    recall  f1-score   support

           0       0.98      0.96      0.97       120
           1       0.94      0.97      0.96        80

    accuracy                           0.96       200
   macro avg       0.96      0.97      0.96       200
weighted avg       0.97      0.96      0.97       200


---

## ğŸ“Š Confusion Matrix  
    [[115   5]
    [ 2  78]]

### ğŸ§  Interpretation  

| Actual | Predicted Fail | Predicted Pass |
| ------ | -------------- | -------------- |
| Fail   | 115 Correct    | 5 Incorrect    |
| Pass   | 2 Incorrect    | 78 Correct     |

âœ” Reduced misclassification  
âœ” Improved recall for passing students  
âœ” Strong generalization capability  

---

## ğŸ–¼ Confusion Matrix Visualization  

Saved as:  
reports/confusion_matrix.png


ğŸ“Œ This image visually represents model classification accuracy.

---

## ğŸ“ˆ Training vs Testing Accuracy  
     Training Accuracy: 1.0
     Testing Accuracy: 0.965

### ğŸ” Overfitting Analysis  

- Training accuracy remains high  
- Testing accuracy is also strong  
- Performance gap is **small**, indicating **good generalization**  
- Model is **not underfitting** and shows **acceptable overfitting**

---

## ğŸ’¾ Model Saved for Deployment  

Saved trained model file:
models/pass_fail_model.pkl


ğŸ“Œ The model can now be reused without retraining.

---

## ğŸ§ª Model Tested on New Student Input  

The model was tested with **new unseen student data**, confirming:

âœ” Accurate predictions  
âœ” Stable output  
âœ” Real-time prediction readiness  

ğŸ“Œ The model is now suitable for integration into a web or decision-support application.

---

## ğŸ“ Academic Justification  

- Real student dataset ensures **scientific credibility**  
- XGBoost selected for **superior accuracy, boosting capability, and feature importance normalization**  
- Evaluation metrics include:
  - Accuracy  
  - Precision  
  - Recall  
  - F1-Score  
  - Confusion Matrix  
- The system demonstrates **strong predictive reliability** for academic decision-making  

---

## ğŸŸ¢ Day 6 â€” Academic Weakness Detection & Recommendation Module

- Created a dedicated `src/recommendation/` module to implement guidance and academic recommendation logic  
- Developed a **weak area detection system** to identify student challenges across multiple dimensions:
  - Academic grades  
  - Attendance patterns  
  - Stress levels  
  - Motivation indicators  
- Designed a **rule-based academic weakness identification framework** that classifies weak areas such as:
  - Low subject performance  
  - Poor attendance behavior  
  - High academic stress  
  - Low motivation and engagement  
- Implemented a **personalized feedback generation engine**, producing tailored recommendations for each detected weakness  
- Converted exploratory notebook logic into a **production-ready Python module** inside `src/`, improving modularity and maintainability  
- Tested the weak-area detection system using **real student data**, validating accuracy and consistency  

ğŸ“Œ This module enables the system to move beyond prediction and begin delivering **actionable academic guidance**.

## ğŸŸ¢ Day 7 â€” Academic Risk Scoring Module

- Developed a **student academic risk scoring algorithm** to assess overall performance risk  
- Classified students into **Low Risk / Medium Risk / High Risk** categories  
- Integrated **risk score results with weak-area detection outputs** to provide more meaningful and actionable academic decision support  

---

## ğŸ¯ Day 8 â€” Planned Step: Course Recommendation System

- Design a **course recommendation engine** based on student performance, interests, and risk level  
- Integrate **course recommendations with academic risk scores** to suggest appropriate learning paths  
- Provide personalized course guidance to support academic improvement and career readiness  
## ğŸ“Œ Project Status (Up to Day 7)

The system now supports student performance prediction using XGBoost.
weak-area detection, personalized feedback, and academic risk classification (Low/Medium/High).
Core analytics and decision-support modules are complete, and development is progressing toward course recommendation integration.

## ğŸ“Œ Author  

**Aman Kumar**  
B.Tech Computer Science & Engineering  
Final Year Major Project  
**Academic Decision Support System (ADSS)**  


